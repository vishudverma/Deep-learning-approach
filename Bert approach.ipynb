{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f655eea6-25ca-4bcf-bb1e-3bf4f2015ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91464c3d-4e71-4734-abe5-bda337351c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the Ultrasound features data from the specified CSV file\n",
    "data_USG = pd.read_csv(\"Features/Ultrasound features.csv\")\n",
    "\n",
    "# Read the Mammogram features data from the specified CSV file\n",
    "data_MMG = pd.read_csv(\"Features/Mammogram features.csv\")\n",
    "\n",
    "# Read the multimodal features data from the specified CSV file\n",
    "data_multimodal = pd.read_csv(\"Features/multimodal features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "646bd2c9-fcab-4291-bfa1-11bb690f958a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate the features and labels\n",
    "features = data_USG.iloc[:, :-1]\n",
    "labels = data_USG.iloc[:, -1]\n",
    "\n",
    "# Convert the labels to numeric values (0 or 1)\n",
    "labels = labels.map({\"class1\": 0, \"class2\": 1})\n",
    "\n",
    "# Convert the features to a list of strings\n",
    "feature_strings = features.astype(str).apply(' '.join, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831c4af-ba85-4d26-ac36-94afe5b0b1d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the feature strings\n",
    "tokenized_inputs = tokenizer(feature_strings, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb1d90-5e2f-4502-bb40-1d9f1e6aad61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the labels to a tensor\n",
    "labels_tensor = torch.tensor(labels.tolist())\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'], labels_tensor)\n",
    "\n",
    "# Set the batch size and create a DataLoader\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, sampler=RandomSampler(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab95503-25e1-4b1d-ab61-0d578f961e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e474e-21ec-4ecb-b2f4-d55610790cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5073f1-5201-4c94-87ec-b008e2157553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Average Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
